[paths]
base_dir = .
models_dir = models
cache_dir = cache
output_dir = output
logs_dir = logs
wheels_dir = wheels
ffmpeg_path = c:\ffmpeg\ffmpeg.exe

[stt]
engine = faster_whisper
model_name = large-v3
device = cuda
compute_type = float32
beam_size = 5
vad_filter = true
language = ru
task = transcribe

[profile]
active = auto

[profile_fast]
model_name = small
compute_type = int8_float32
beam_size = 1

[profile_balanced]
model_name = medium
compute_type = int8_float32
beam_size = 4

[profile_quality]
model_name = large-v3
compute_type = float32
beam_size = 5

[profile_auto]
short_max_minutes = 0.5
medium_max_minutes = 6
short_profile = quality
medium_profile = balanced
long_profile = fast


[summarize]
enabled = true
; режим: local | cloud | auto
ollama_mode = auto
; куда ходить за локальными моделями
ollama_url_local = http://127.0.0.1:11434
; куда ходить за cloud-моделями
ollama_url_cloud = https://ollama.com
; имя переменной окружения, где лежит ключ (НЕ сам ключ!)
ollama_api_key_env = OLLAMA_API_KEY
model = gemma2:2b
prompt_template = prompts/meeting_ru.txt
timeout_s = 120
max_chars = 18000
stream = false

[export]
save_txt = true
save_json = true
save_md = true
include_timestamps = true
filename_mode = timestamp
